{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/daskoushik/resnet50-on-sign-language-classification?scriptVersionId=114315313\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Packages","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image, image_dataset_from_directory\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import random_uniform, glorot_uniform\nfrom tensorflow.keras.models import Sequential, save_model, load_model\nfrom matplotlib.pyplot import imshow\nimport matplotlib.pyplot as plt\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-20T07:59:35.072524Z","iopub.execute_input":"2022-12-20T07:59:35.073044Z","iopub.status.idle":"2022-12-20T07:59:35.081051Z","shell.execute_reply.started":"2022-12-20T07:59:35.072993Z","shell.execute_reply":"2022-12-20T07:59:35.080044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet50 Model:\n* **identity_block**: contains three main components consisting of Convolutional->BathNorm->ReLU layers and a skip connection\n* **convolutional_block**: contains three main components consisting of Convolutional->BathNorm->ReLU layers and a skip connection with a Convolutional->BathNorm Layers\n* **ResNet50**: Uses identity and conolutional blocks to create a deep CNN with a total of 50 layers","metadata":{}},{"cell_type":"code","source":"def identity_block(X, f, filters, training=True, initializer=random_uniform):\n    \"\"\"    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    training -- True: Behave in training mode\n                False: Behave in inference mode\n    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n    \n    Returns:\n    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n    \"\"\"\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n    X = Activation('relu')(X)\n    \n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = f, strides = 1, padding = 'same', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    \n    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training)\n    \n    X = Add()([X_shortcut, X])\n    X = Activation('relu')(X)\n\n    return X","metadata":{"execution":{"iopub.status.busy":"2022-12-20T07:59:35.300718Z","iopub.execute_input":"2022-12-20T07:59:35.301557Z","iopub.status.idle":"2022-12-20T07:59:35.311161Z","shell.execute_reply.started":"2022-12-20T07:59:35.301513Z","shell.execute_reply":"2022-12-20T07:59:35.31018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n    \"\"\"\n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    s -- Integer, specifying the stride to be used\n    training -- True: Behave in training mode\n                False: Behave in inference mode\n    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n                   also called Xavier uniform initializer.\n    \n    Returns:\n    X -- output of the convolutional block, tensor of shape (m, n_H, n_W, n_C)\n    \"\"\"\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training=training)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = f, strides = 1, padding = 'same', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training)\n    \n    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s,s), padding = 'valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training = training)\n    \n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","metadata":{"execution":{"iopub.status.busy":"2022-12-20T07:59:35.544278Z","iopub.execute_input":"2022-12-20T07:59:35.545075Z","iopub.status.idle":"2022-12-20T07:59:35.556509Z","shell.execute_reply.started":"2022-12-20T07:59:35.545036Z","shell.execute_reply":"2022-12-20T07:59:35.555523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ResNet50(input_shape = (200, 200, 3), classes = 6):\n    \"\"\"\n    Stage-wise implementation of the architecture of the popular ResNet50:\n    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n\n    Arguments:\n    input_shape -- shape of the images of the dataset\n    classes -- integer, number of classes\n\n    Returns:\n    model -- a Model() instance in Keras\n    \"\"\"\n    X_input = Input(input_shape)\n\n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n    X = identity_block(X, 3, [64, 64, 256])\n    X = identity_block(X, 3, [64, 64, 256])\n    \n    # Stage 3\n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2) \n    X = identity_block(X, 3, [128, 128, 512])\n    X = identity_block(X, 3, [128, 128, 512])\n    X = identity_block(X, 3, [128, 128, 512]) \n    \n    # Stage 4\n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2) \n    X = identity_block(X, 3, [256, 256, 1024]) \n    X = identity_block(X, 3, [256, 256, 1024]) \n    X = identity_block(X, 3, [256, 256, 1024]) \n    X = identity_block(X, 3, [256, 256, 1024]) \n    X = identity_block(X, 3, [256, 256, 1024]) \n\n    # Stage 5\n    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2) \n    X = identity_block(X, 3, [512, 512, 2048])  \n    X = identity_block(X, 3, [512, 512, 2048])  \n\n    X = AveragePooling2D((2,2))(X)\n    \n    # output layer\n    X = Flatten()(X)\n    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    \n    model = Model(inputs = X_input, outputs = X)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-20T07:59:35.872304Z","iopub.execute_input":"2022-12-20T07:59:35.87285Z","iopub.status.idle":"2022-12-20T07:59:35.887472Z","shell.execute_reply.started":"2022-12-20T07:59:35.872821Z","shell.execute_reply":"2022-12-20T07:59:35.88652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nIMG_SIZE = (200, 200)\ndirectory = \"/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train\"\ntrain_dataset = image_dataset_from_directory(directory,\n                                             shuffle=True,\n                                             batch_size=BATCH_SIZE,\n                                             image_size=IMG_SIZE,\n                                             validation_split=0.2,\n                                             subset='training',\n                                             label_mode = 'categorical',\n                                             seed=20)\nvalidation_dataset = image_dataset_from_directory(directory,\n                                             shuffle=True,\n                                             batch_size=BATCH_SIZE,\n                                             image_size=IMG_SIZE,\n                                             validation_split=0.2,\n                                             subset='validation',\n                                             label_mode = 'categorical',\n                                             seed=20)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T07:59:36.280729Z","iopub.execute_input":"2022-12-20T07:59:36.281152Z","iopub.status.idle":"2022-12-20T08:00:28.145521Z","shell.execute_reply.started":"2022-12-20T07:59:36.281108Z","shell.execute_reply":"2022-12-20T08:00:28.144507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = train_dataset.class_names\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T08:00:28.147453Z","iopub.execute_input":"2022-12-20T08:00:28.147912Z","iopub.status.idle":"2022-12-20T08:00:28.155789Z","shell.execute_reply.started":"2022-12-20T08:00:28.147864Z","shell.execute_reply":"2022-12-20T08:00:28.154626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, labels in train_dataset.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"int\"))\n        plt.title(class_names[np.argmax(labels[i])])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-12-20T08:00:28.15728Z","iopub.execute_input":"2022-12-20T08:00:28.158163Z","iopub.status.idle":"2022-12-20T08:00:30.087029Z","shell.execute_reply.started":"2022-12-20T08:00:28.158123Z","shell.execute_reply":"2022-12-20T08:00:30.086076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\nvalidation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T08:00:30.089242Z","iopub.execute_input":"2022-12-20T08:00:30.090179Z","iopub.status.idle":"2022-12-20T08:00:30.112401Z","shell.execute_reply.started":"2022-12-20T08:00:30.090142Z","shell.execute_reply":"2022-12-20T08:00:30.110683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"model = ResNet50(input_shape = (200, 200, 3), classes = 29)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-20T08:00:30.114045Z","iopub.execute_input":"2022-12-20T08:00:30.114597Z","iopub.status.idle":"2022-12-20T08:00:31.284024Z","shell.execute_reply.started":"2022-12-20T08:00:30.114526Z","shell.execute_reply":"2022-12-20T08:00:31.277594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Model\nCommenting these as I've already saved my model and then imported as a dataset. You can run these if you want, the training acc - >99%, val acc - >99%","metadata":{}},{"cell_type":"code","source":"# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-12-20T08:00:31.285308Z","iopub.execute_input":"2022-12-20T08:00:31.285857Z","iopub.status.idle":"2022-12-20T08:00:31.299797Z","shell.execute_reply.started":"2022-12-20T08:00:31.285818Z","shell.execute_reply":"2022-12-20T08:00:31.298772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.fit(train_dataset, validation_data=validation_dataset, epochs=5)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T21:09:18.872296Z","iopub.execute_input":"2022-12-19T21:09:18.872683Z","iopub.status.idle":"2022-12-19T21:41:20.189035Z","shell.execute_reply.started":"2022-12-19T21:09:18.872653Z","shell.execute_reply":"2022-12-19T21:41:20.188046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# acc = [0.] + model.history.history['accuracy']\n# val_acc = [0.] + model.history.history['val_accuracy']\n\n# loss = model.history.history['loss']\n# val_loss = model.history.history['val_loss']\n\n# plt.figure(figsize=(8, 8))\n# plt.subplot(2, 1, 1)\n# plt.plot(acc, label='Training Accuracy')\n# plt.plot(val_acc, label='Validation Accuracy')\n# plt.legend(loc='lower right')\n# plt.ylabel('Accuracy')\n# plt.ylim([min(plt.ylim()),1])\n# plt.title('Training and Validation Accuracy')\n\n# plt.subplot(2, 1, 2)\n# plt.plot(loss, label='Training Loss')\n# plt.plot(val_loss, label='Validation Loss')\n# plt.legend(loc='upper right')\n# plt.ylabel('Cross Entropy')\n# plt.ylim([0,1.0])\n# plt.title('Training and Validation Loss')\n# plt.xlabel('epoch')\n# plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save(\"modelASL.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-12-19T22:24:23.719083Z","iopub.execute_input":"2022-12-19T22:24:23.719473Z","iopub.status.idle":"2022-12-19T22:24:24.159151Z","shell.execute_reply.started":"2022-12-19T22:24:23.719439Z","shell.execute_reply":"2022-12-19T22:24:24.158005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating on test set","metadata":{}},{"cell_type":"code","source":"model = load_model('/kaggle/input/resnet50asl/modelASL.h5')","metadata":{"execution":{"iopub.status.busy":"2022-12-20T08:02:42.330244Z","iopub.execute_input":"2022-12-20T08:02:42.330605Z","iopub.status.idle":"2022-12-20T08:02:47.487077Z","shell.execute_reply.started":"2022-12-20T08:02:42.330574Z","shell.execute_reply":"2022-12-20T08:02:47.485978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor i in range(28):\n    ax = plt.subplot(5, 6, i + 1)\n    img_path = f\"/kaggle/input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/%s_test.jpg\"%chr(65+i)\n    if i == 26:\n        img_path = \"/kaggle/input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/nothing_test.jpg\"\n    if i == 27:\n        img_path = \"/kaggle/input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/space_test.jpg\"\n    img = image.load_img(img_path, target_size=(200, 200))\n    img_array = image.img_to_array(img)\n    img_batch = np.expand_dims(img_array, axis=0)\n    plt.imshow(img)\n    plt.title(np.argmax(model.predict(img_batch)))\n    plt.axis(\"off\")\n","metadata":{"execution":{"iopub.status.busy":"2022-12-20T08:03:08.57136Z","iopub.execute_input":"2022-12-20T08:03:08.571729Z","iopub.status.idle":"2022-12-20T08:03:11.394498Z","shell.execute_reply.started":"2022-12-20T08:03:08.571699Z","shell.execute_reply":"2022-12-20T08:03:11.393674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion:\n* Can not say about the model performance as the test set was small. Gotta change the train/val/test spilt and see the performance.\n* It classified all of the above images correctly except for the letter 'A'","metadata":{}}]}